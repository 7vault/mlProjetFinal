# D√©tecteur de commentaire toxique

##Objective

The goal of this project is to develop a machine learning model capable of detecting toxic comments on an online platform like a church website or a school forum.
The model will be trained on a dataset labeled with toxic and non-toxic comments, and will be used to predict the toxicity
of new comments.

üìù

### User Stories

-As a user, I want to be able to submit a comment to the platform to determine if it is toxic or not.
-As a user, I want to be able to see previously submitted comments and their toxicity level.
-As an administrator, I want to be able to use the machine learning model to automatically detect toxic
comments and take action to remove them.

#### Features

- [x] Users will be able to submit comments to determine if they are toxic or not.

### App Walkthough GIF

<img src="toxicity.gif" width=250><br>

Installation
To run the project, the following Python libraries must be installed:

scikit-learn
TensorFlow
PyTorch
Pandas
NumPy
These libraries can be installed using pip, the Python package manager.

Execution
The project can be run by executing the CommentToxicity_MLProject.ipynb file with Python. The training data can be found in the folder "jigsaw-toxic-comment-classification-challenge" and the trained models can be found in the file "toxic_comment_detector.h5". The file "config.py" can be used to modify the model parameters and hyperparameters.

Conclusion
This project aims to provide an online platform capable of detecting toxic comments. We hope that this will help to improve safety and inclusion on online platforms.

This project has been realised by:

Jennifer BOURDEAU
Lorvenson CONSTANT
Wendy NESTAND
Blanjina PROSPERE
Luckson SURPRICE
